{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6f8ee94c255eb1f45edb80e83721093c1db1e2ea85447c0854292673b957abb8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Cloning into 'ds_cup'...\nerror: cannot spawn sh: No such file or directory\nfatal: could not read Username for 'https://github.com': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/KushajveerSingh/ds_cup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, recall_score,precision_score\n",
    "smallestF =  np.finfo('float').eps # smallest float value (numpy), will be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data_orig')\n",
    "# path = Path('ds_cup/orig_data')\n",
    "orig_train_df = pd.read_csv(path/'train.csv')\n",
    "orig_valid_df = pd.read_csv(path/'valid.csv')\n",
    "orig_test_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix Name error:\n",
    "orig_train_df.rename(columns={'auto_open_ 36_month_num': 'auto_open_36_month_num'},inplace=True)\n",
    "orig_valid_df.rename(columns={'auto_open_ 36_month_num': 'auto_open_36_month_num'},inplace=True)\n",
    "orig_test_df.rename(columns={'auto_open_ 36_month_num': 'auto_open_36_month_num'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size(df, name):\n",
    "    counts = df['Default_ind'].value_counts()\n",
    "    print(f'{name} dataset')\n",
    "    print(f'Num 0 values = {counts[0]}')\n",
    "    print(f'Num 1 values = {counts[1]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train dataset\nNum 0 values = 18414\nNum 1 values = 1586\n\nvalid dataset\nNum 0 values = 2778\nNum 1 values = 222\n\ntest dataset\nNum 0 values = 4599\nNum 1 values = 401\n\n"
     ]
    }
   ],
   "source": [
    "print_size(orig_train_df, 'train')\n",
    "print_size(orig_valid_df, 'valid')\n",
    "print_size(orig_test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tot_credit_debt                          0\navg_card_debt                            0\ncredit_age                               0\ncredit_good_age                          0\ncard_age                                 0\nnon_mtg_acc_past_due_12_months_num       0\nnon_mtg_acc_past_due_6_months_num        0\nmortgages_past_due_6_months_num          0\ncredit_past_due_amount                   0\ninq_12_month_num                         0\ncard_inq_24_month_num                    0\ncard_open_36_month_num                   0\nauto_open_36_month_num                   0\nuti_card                                 0\nuti_50plus_pct                           0\nuti_max_credit_line                      0\nuti_card_50plus_pct                   2055\nind_acc_XYZ                              0\nrep_income                            1570\nStates                                   0\nDefault_ind                              0\ndtype: int64\n--\ntot_credit_debt                         0\navg_card_debt                           0\ncredit_age                              0\ncredit_good_age                         0\ncard_age                                0\nnon_mtg_acc_past_due_12_months_num      0\nnon_mtg_acc_past_due_6_months_num       0\nmortgages_past_due_6_months_num         0\ncredit_past_due_amount                  0\ninq_12_month_num                        0\ncard_inq_24_month_num                   0\ncard_open_36_month_num                  0\nauto_open_36_month_num                  0\nuti_card                                0\nuti_50plus_pct                          0\nuti_max_credit_line                     0\nuti_card_50plus_pct                   297\nind_acc_XYZ                             0\nrep_income                            253\nStates                                  0\nDefault_ind                             0\ndtype: int64\n--\ntot_credit_debt                         0\navg_card_debt                           0\ncredit_age                              0\ncredit_good_age                         0\ncard_age                                0\nnon_mtg_acc_past_due_12_months_num      0\nnon_mtg_acc_past_due_6_months_num       0\nmortgages_past_due_6_months_num         0\ncredit_past_due_amount                  0\ninq_12_month_num                        0\ncard_inq_24_month_num                   0\ncard_open_36_month_num                  0\nauto_open_36_month_num                  0\nuti_card                                0\nuti_50plus_pct                          0\nuti_max_credit_line                     0\nuti_card_50plus_pct                   499\nind_acc_XYZ                             0\nrep_income                            383\nStates                                  0\nDefault_ind                             0\ndtype: int64\n--\n"
     ]
    }
   ],
   "source": [
    "print(orig_train_df.isnull().sum())\n",
    "print('--')\n",
    "print(orig_valid_df.isnull().sum())\n",
    "print('--')\n",
    "print(orig_test_df.isnull().sum())\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createThreshDict(colName,Arr):\n",
    "    _dict = {}\n",
    "    _dict['colName'] = colName\n",
    "    _dict['ThreshArr'] = Arr\n",
    "    return _dict\n",
    "def binColumn(col,threshArr):\n",
    "    assert col.isnull().all() != True, \"All values are null?\"\n",
    "    def binVal(val):\n",
    "        loc = 1\n",
    "        for x in threshArr:\n",
    "            if(val<=x):\n",
    "                return loc\n",
    "            else:\n",
    "                loc = loc+1\n",
    "        return loc\n",
    "    theCol = col.copy()\n",
    "    threshArr = np.sort(np.array(threshArr))\n",
    "    #Replace Nulls with 0 if any\n",
    "    theBinnedCol = []\n",
    "    for val in theCol:\n",
    "        if(not np.isnan(val)):\n",
    "            theBinnedCol.extend([binVal(val)])\n",
    "        else:\n",
    "            theBinnedCol.extend([0])\n",
    "        #theCol.update(pd.Series([], index=[ind]))\n",
    "    return pd.Series(theBinnedCol,index=col.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDataBinClean(DF):\n",
    "    DFThresh =  pd.DataFrame(columns=createThreshDict(\"\",[]).keys())\n",
    "    DF_Cleaned = pd.DataFrame(columns=DF.columns)\n",
    "    #--'tot_credit_debt'--\n",
    "    _col = 'tot_credit_debt'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'avg_card_debt'--\n",
    "    cutoff_avg_card_debt = (13167.825020 + 99999.0)/2\n",
    "    _col = 'avg_card_debt'\n",
    "    _thresh = DF[DF.avg_card_debt < cutoff_avg_card_debt]['avg_card_debt'].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    _thresh = np.append(_thresh, [cutoff_avg_card_debt])\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'credit_age'--\n",
    "    _col = 'credit_age'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'credit_good_age'--\n",
    "    _col = 'credit_good_age'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'card_age'--\n",
    "    _col = 'card_age'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'non_mtg_acc_past_due_12_months_num'--\n",
    "    DF_Cleaned['non_mtg_acc_past_due_12_months_num'] = DF['non_mtg_acc_past_due_12_months_num'].copy()\n",
    "    #--'non_mtg_acc_past_due_6_months_num'--\n",
    "    DF_Cleaned['non_mtg_acc_past_due_6_months_num'] = DF['non_mtg_acc_past_due_6_months_num'].copy()\n",
    "    #--'mortgages_past_due_6_months_num'--\n",
    "    DF_Cleaned['mortgages_past_due_6_months_num'] = DF['mortgages_past_due_6_months_num'].copy()\n",
    "    #--'credit_past_due_amount'--\n",
    "    _col = 'credit_past_due_amount'\n",
    "    _thresh = DF[DF.credit_past_due_amount > 0][_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    _thresh = np.insert(_thresh, 0, 0+smallestF)\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'inq_12_month_num'--\n",
    "    _col = 'inq_12_month_num'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'card_inq_24_month_num'--\n",
    "    _col = 'card_inq_24_month_num'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'card_open_36_month_num'--\n",
    "    _col = 'card_open_36_month_num'\n",
    "    DF_Cleaned[_col] = DF[_col].copy()\n",
    "    #--'auto_open_ 36_month_num'--\n",
    "    _col = 'auto_open_36_month_num'\n",
    "    DF_Cleaned[_col] = DF[_col].copy()\n",
    "    #--'uti_card'--\n",
    "    _col = 'uti_card'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'uti_50plus_pct'--\n",
    "    _col = 'uti_50plus_pct'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'uti_max_credit_line'--\n",
    "    _col = 'uti_max_credit_line'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'uti_card_50plus_pct'--\n",
    "    _col = 'uti_card_50plus_pct'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'ind_acc_XYZ'--\n",
    "    _col = 'ind_acc_XYZ'\n",
    "    DF_Cleaned[_col] = DF[_col].copy()\n",
    "    #--'rep_income'--\n",
    "    _col = 'rep_income'\n",
    "    _thresh = DF[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "    DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "        _thresh),\n",
    "        ignore_index=True) \n",
    "    DF_Cleaned[_col] = binColumn(DF[_col],_thresh)\n",
    "    #--'States'--\n",
    "    _col = 'States'\n",
    "    enc = OneHotEncoder(handle_unknown='ignore',sparse = False)\n",
    "    SM = enc.fit_transform(DF[_col].to_numpy().reshape(-1,1)) #Got it!\n",
    "    for ind,cat in zip(range(0,len(enc.categories_[0])),enc.categories_[0]):\n",
    "        DF_Cleaned.drop(columns=['is'+str(cat)],inplace=True,errors='ignore')\n",
    "        DF_Cleaned.insert(0,'is'+str(cat), SM[:,ind]) # Inserted column names are isAK, isAL, isDC..etc. \n",
    "    #And it will contain 0 if that is not the state and 1 if that is the state,\n",
    "    DF_Cleaned.drop(columns=[_col],inplace=True) #Remove States Column\n",
    "    #--'Default_ind'--\n",
    "    _col = 'Default_ind'\n",
    "    DF_Cleaned[_col] = DF[_col].copy()\n",
    "    #--\n",
    "    return DF_Cleaned,DFThresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binDataFrameWithThresh(DF,ThreshDF):\n",
    "    DF_Cleaned = DF.copy()\n",
    "    for col,arr in zip(ThreshDF.colName.values,ThreshDF.ThreshArr.values):\n",
    "        DF_Cleaned[col] = binColumn(DF[col],arr)\n",
    "    return DF_Cleaned\n",
    "def oneHotEncodeStates(DF):\n",
    "    _col = 'States'\n",
    "    DF_Fixed = DF.copy()\n",
    "    enc = OneHotEncoder(handle_unknown='ignore',sparse = False)\n",
    "    SM = enc.fit_transform(DF[_col].to_numpy().reshape(-1,1)) #Got it!\n",
    "    for ind,cat in zip(range(0,len(enc.categories_[0])),enc.categories_[0]):\n",
    "        DF_Fixed.drop(columns=['is'+str(cat)],inplace=True,errors='ignore')\n",
    "        DF_Fixed.insert(0,'is'+str(cat), SM[:,ind]) # Inserted column names are isAK, isAL, isDC..etc. \n",
    "    #And it will contain 0 if that is not the state and 1 if that is the state,\n",
    "    DF_Fixed.drop(columns=[_col],inplace=True) #Remove States Column\n",
    "    return DF_Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_thresh = trainDataBinClean(orig_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = binDataFrameWithThresh(orig_valid_df,df_thresh) # Binning Validation data using thresholds of training data\n",
    "df_valid = oneHotEncodeStates(df_valid) #States\n",
    "#Same ops on test data\n",
    "df_test = binDataFrameWithThresh(orig_test_df,df_thresh)\n",
    "df_test = oneHotEncodeStates(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.to_csv(path/'train_binned.csv',index=None)\n",
    "df_thresh.to_csv(path/'Thresholds.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1) #Shuffle!\n",
    "df_trainX = df_train.iloc[:,:-1]\n",
    "df_trainY = df_train.iloc[:,-1]\n",
    "#\n",
    "df_valid = df_valid.sample(frac=1)\n",
    "df_validX = df_valid.iloc[:,:-1]\n",
    "df_validY = df_valid.iloc[:,-1]\n",
    "#\n",
    "df_test = df_test.sample(frac=1)\n",
    "df_testX = df_test.iloc[:,:-1]\n",
    "df_testY = df_test.iloc[:,-1]"
   ]
  },
  {
   "source": [
    "# --- Dataframes Ready ---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Sample Logistic Regression Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced',solver='liblinear')\n",
    "scores = cross_validate(model, df_trainX, df_trainY, cv=10,scoring=('accuracy','recall','precision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_recall  test_precision\n",
       "0  0.247677    0.011208         0.7365     0.639241        0.176883\n",
       "1  0.218529    0.005000         0.7385     0.683544        0.185886\n",
       "2  0.221690    0.005998         0.7565     0.645570        0.191370\n",
       "3  0.204042    0.006003         0.7715     0.670886        0.207436\n",
       "4  0.166039    0.004998         0.7650     0.647799        0.199226\n",
       "5  0.217050    0.005000         0.7410     0.679245        0.187826\n",
       "6  0.205042    0.005001         0.7780     0.660377        0.212121\n",
       "7  0.220051    0.005001         0.7625     0.679245        0.203008\n",
       "8  0.202043    0.005001         0.7560     0.603774        0.184261\n",
       "9  0.217047    0.005000         0.7665     0.628931        0.196850"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_accuracy</th>\n      <th>test_recall</th>\n      <th>test_precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.247677</td>\n      <td>0.011208</td>\n      <td>0.7365</td>\n      <td>0.639241</td>\n      <td>0.176883</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.218529</td>\n      <td>0.005000</td>\n      <td>0.7385</td>\n      <td>0.683544</td>\n      <td>0.185886</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.221690</td>\n      <td>0.005998</td>\n      <td>0.7565</td>\n      <td>0.645570</td>\n      <td>0.191370</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.204042</td>\n      <td>0.006003</td>\n      <td>0.7715</td>\n      <td>0.670886</td>\n      <td>0.207436</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.166039</td>\n      <td>0.004998</td>\n      <td>0.7650</td>\n      <td>0.647799</td>\n      <td>0.199226</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.217050</td>\n      <td>0.005000</td>\n      <td>0.7410</td>\n      <td>0.679245</td>\n      <td>0.187826</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.205042</td>\n      <td>0.005001</td>\n      <td>0.7780</td>\n      <td>0.660377</td>\n      <td>0.212121</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.220051</td>\n      <td>0.005001</td>\n      <td>0.7625</td>\n      <td>0.679245</td>\n      <td>0.203008</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.202043</td>\n      <td>0.005001</td>\n      <td>0.7560</td>\n      <td>0.603774</td>\n      <td>0.184261</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.217047</td>\n      <td>0.005000</td>\n      <td>0.7665</td>\n      <td>0.628931</td>\n      <td>0.196850</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "cv_scores = pd.DataFrame(scores)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Cross Validation Results\nAccuracy = 0.7572\nRecall = 0.6538611575511504\nPrecision = 0.19448676236244716\n"
     ]
    }
   ],
   "source": [
    "print('Average Cross Validation Results')\n",
    "print('Accuracy =',np.average(cv_scores.test_accuracy))\n",
    "print('Recall =',np.average(cv_scores.test_recall))\n",
    "print('Precision =',np.average(cv_scores.test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogisticRegression(penalty='l1',class_weight='balanced',solver='liblinear')\n",
    "hist = model2.fit(df_trainX,df_trainY)\n",
    "df_validYPred = model2.predict(df_validX)"
   ]
  },
  {
   "source": [
    "accScore = accuracy_score(df_validY,df_validYPred)\n",
    "recScore = recall_score(df_validY,df_validYPred)\n",
    "preScore = precision_score(df_validY,df_validYPred)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.7903333333333333\nRecall = 0.6081081081081081\nPrecision = 0.19940915805022155\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy =',accScore)\n",
    "print('Recall =',recScore)\n",
    "print('Precision =',preScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Predicted   0.0  1.0\n",
       "Actual              \n",
       "0.0        2236  542\n",
       "1.0          87  135"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Predicted</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>Actual</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>2236</td>\n      <td>542</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>87</td>\n      <td>135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "pd.crosstab(pd.Series(df_validY.values,name='Actual'),pd.Series(df_validYPred,name='Predicted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 Score 0.3003337041156841\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score', f1_score(df_validY,df_validYPred))"
   ]
  }
 ]
}