{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6f8ee94c255eb1f45edb80e83721093c1db1e2ea85447c0854292673b957abb8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/KushajveerSingh/ds_cup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallestF =  np.finfo('float').eps # smallest float value (numpy), will be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data_orig')\n",
    "# path = Path('ds_cup/orig_data')\n",
    "orig_train_df = pd.read_csv(path/'train.csv')\n",
    "orig_valid_df = pd.read_csv(path/'valid.csv')\n",
    "orig_test_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size(df, name):\n",
    "    counts = df['Default_ind'].value_counts()\n",
    "    print(f'{name} dataset')\n",
    "    print(f'Num 0 values = {counts[0]}')\n",
    "    print(f'Num 1 values = {counts[1]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_size(orig_train_df, 'train')\n",
    "print_size(orig_valid_df, 'valid')\n",
    "print_size(orig_test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def binColumn(col):\n",
    "def binColumn(col,threshArr):\n",
    "    assert col.isnull().all() != True, \"All values are null?\"\n",
    "    def binVal(val):\n",
    "        loc = 1\n",
    "        for x in threshArr:\n",
    "            if(val<=x):\n",
    "                return loc\n",
    "            else:\n",
    "                loc = loc+1\n",
    "        return loc\n",
    "    theCol = col.copy()\n",
    "    threshArr = np.sort(np.array(threshArr))\n",
    "    #Replace Nulls with 0 if any\n",
    "    theBinnedCol = []\n",
    "    for val in theCol:\n",
    "        if(not np.isnan(val)):\n",
    "            theBinnedCol.extend([binVal(val)])\n",
    "        else:\n",
    "            theBinnedCol.extend([0])\n",
    "        #theCol.update(pd.Series([], index=[ind]))\n",
    "    return pd.Series(theBinnedCol,index=col.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createThreshDict(colName,Arr):\n",
    "    _dict = {}\n",
    "    _dict['colName'] = colName\n",
    "    _dict['ThreshArr'] = Arr\n",
    "    return _dict\n",
    "DFThresh =  pd.DataFrame(columns=createThreshDict(\"\",[]).keys())"
   ]
  },
  {
   "source": [
    "- Going through all columns one by one and applying binning and solving Null Problems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#orig_train_df = orig_train_df.sample(frac=1) #Shuffling the dataset before using\n",
    "#orig_valid_df = orig_valid_df.sample(frac=1) #Shuffling the dataset before using\n",
    "#orig_test_df = orig_test_df.sample(frac=1) #Shuffling the dataset before using\n",
    "train_df = pd.DataFrame(columns=orig_train_df.columns)\n",
    "#valid_df = pd.DataFrame(columns=orig_valid_df.columns)\n",
    "#test_df = pd.DataFrame(columns=orig_valid_df.columns)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df.columns"
   ]
  },
  {
   "source": [
    "## - tot_credit_debt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'tot_credit_debt'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - avg_card_debt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_avg_card_debt = (19960.610000 + 99999.0)/2\n",
    "cutoff_avg_card_debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13167.825 (cutoff) is max value of lower cluster and 99999 is value of next one\n",
    "orig_train_df[orig_train_df.avg_card_debt > cutoff_avg_card_debt]['avg_card_debt'].describe(),orig_train_df[orig_train_df.avg_card_debt < cutoff_avg_card_debt]['avg_card_debt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Column = avg_card_debt')\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(orig_train_df[orig_train_df.avg_card_debt > cutoff_avg_card_debt]['avg_card_debt'],'ro',marker='*',)\n",
    "ax[1].plot(orig_train_df[orig_train_df.avg_card_debt < cutoff_avg_card_debt]['avg_card_debt'],'ro',marker='*',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'avg_card_debt'\n",
    "_thresh = orig_train_df[orig_train_df.avg_card_debt < cutoff_avg_card_debt]['avg_card_debt'].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "_thresh = np.append(_thresh, [cutoff_avg_card_debt])\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - credit_age"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'credit_age'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - credit_good_age"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'credit_good_age'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - card_age"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'card_age'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - non_mtg_acc_past_due_12_months_num"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_train_df.non_mtg_acc_past_due_12_months_num.value_counts()) #Already binned\n",
    "train_df['non_mtg_acc_past_due_12_months_num'] = orig_train_df['non_mtg_acc_past_due_12_months_num'].copy()"
   ]
  },
  {
   "source": [
    "## - non_mtg_acc_past_due_6_months_num"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_train_df.non_mtg_acc_past_due_6_months_num.value_counts()) #Already Binned\n",
    "train_df['non_mtg_acc_past_due_6_months_num'] = orig_train_df['non_mtg_acc_past_due_6_months_num'].copy()"
   ]
  },
  {
   "source": [
    "## - mortgages_past_due_6_months_num"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_train_df.mortgages_past_due_6_months_num.value_counts()) #Already Binned\n",
    "train_df['mortgages_past_due_6_months_num'] = orig_train_df['mortgages_past_due_6_months_num'].copy()"
   ]
  },
  {
   "source": [
    "## - credit_past_due_amount"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df.credit_past_due_amount.describe() #Binning Problem, 0 must be seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df[orig_train_df.credit_past_due_amount > 0].credit_past_due_amount.describe() #Binning Problem, 0 must be seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(orig_train_df.credit_past_due_amount[orig_train_df.credit_past_due_amount > 0],'ro',marker='*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'credit_past_due_amount'\n",
    "_thresh = orig_train_df[orig_train_df.credit_past_due_amount > 0][_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "_thresh = np.insert(_thresh, 0, 0+smallestF)\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - inq_12_month_num"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'inq_12_month_num'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - card_inq_24_month_num"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'card_inq_24_month_num'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - card_open_36_month_num  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'card_open_36_month_num'\n",
    "print(orig_train_df[_col].value_counts()) #Already Binned\n",
    "train_df[_col] = orig_train_df[_col].copy()"
   ]
  },
  {
   "source": [
    "## - auto_open_36_month_num"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'auto_open_ 36_month_num'\n",
    "print(orig_train_df[_col].value_counts()) #Already Binned\n",
    "train_df[_col] = orig_train_df[_col].copy()"
   ]
  },
  {
   "source": [
    "## - uti_card"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'uti_card'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - uti_50plus_pct"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'uti_50plus_pct'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - uti_max_credit_line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'uti_max_credit_line'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - uti_card_50plus_pct"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'uti_card_50plus_pct'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - ind_acc_XYZ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'ind_acc_XYZ'\n",
    "print(orig_train_df[_col].value_counts()) #Already Binned\n",
    "train_df[_col] = orig_train_df[_col].copy()"
   ]
  },
  {
   "source": [
    "## - rep_income"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'rep_income'\n",
    "_thresh = orig_train_df[_col].quantile([0.2,0.4,0.6,0.8]).to_numpy()\n",
    "DFThresh = DFThresh.append(createThreshDict(_col,\n",
    "    _thresh),\n",
    "    ignore_index=True) \n",
    "train_df[_col] = binColumn(orig_train_df[_col],_thresh)"
   ]
  },
  {
   "source": [
    "## - States"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'States'\n",
    "#\n",
    "train_df.drop(columns=[_col],inplace=True,errors='ignore')\n",
    "train_df.insert(0,_col,orig_train_df[_col].copy())\n",
    "#\n",
    "enc = OneHotEncoder(handle_unknown='ignore',sparse = False)\n",
    "SM = enc.fit_transform(orig_train_df[_col].to_numpy().reshape(-1,1)) #Got it!\n",
    "for ind,cat in zip(range(0,len(enc.categories_[0])),enc.categories_[0]):\n",
    "    train_df.drop(columns=['is'+str(cat)],inplace=True,errors='ignore')\n",
    "    train_df.insert(0,'is'+str(cat), SM[:,ind]) # Inserted column names are isAK, isAL, isDC..etc. \n",
    "   #And it will contain 0 if that is not the state and 1 if that is the state,\n",
    "#train_df.drop(columns=[_col],inplace=True) #Remove States Column"
   ]
  },
  {
   "source": [
    "## - Default_ind (Output Column)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = 'Default_ind'\n",
    "print(orig_train_df[_col].value_counts()) #Already Binned\n",
    "train_df[_col] = orig_train_df[_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFThresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(path/'train_binned.csv',index=None)\n",
    "DFThresh.to_csv(path/'Thresholds.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df.groupby(by=['States']).std()['rep_income']"
   ]
  }
 ]
}